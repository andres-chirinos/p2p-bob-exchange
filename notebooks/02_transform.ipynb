{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ff8254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (2.3.2)\n",
      "Requirement already satisfied: pyarrow in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (21.0.0)\n",
      "Requirement already satisfied: fastparquet in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (2024.11.0)\n",
      "Requirement already satisfied: kaggle in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (1.7.4.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: cramjam>=2.3 in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from fastparquet) (2.11.0)\n",
      "Requirement already satisfied: fsspec in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from fastparquet) (2025.10.0)\n",
      "Requirement already satisfied: packaging in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: bleach in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (2025.8.3)\n",
      "Requirement already satisfied: charset-normalizer in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (3.4.3)\n",
      "Requirement already satisfied: idna in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (6.32.0)\n",
      "Requirement already satisfied: python-slugify in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages (from kaggle) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip \n",
    "%pip install pandas pyarrow fastparquet kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3639ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, re, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2544b345",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Could not find kaggle.json. Make sure it's located in /home/andreschirinos/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkaggle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkaggle_api_extended\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KaggleApi\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages/kaggle/__init__.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkaggle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkaggle_api_extended\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KaggleApi\n\u001b[32m      5\u001b[39m api = KaggleApi()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauthenticate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/Archivos/Documents/GitHub/p2p-bob-exchange/.venv/lib64/python3.13/site-packages/kaggle/api/kaggle_api_extended.py:434\u001b[39m, in \u001b[36mKaggleApi.authenticate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    433\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mCould not find \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. Make sure it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33ms located in\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    435\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. Or use the environment method. See setup\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    436\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33m instructions at\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    437\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33m https://github.com/Kaggle/kaggle-api/\u001b[39m\u001b[33m'\u001b[39m.format(\n\u001b[32m    438\u001b[39m                       \u001b[38;5;28mself\u001b[39m.config_file, \u001b[38;5;28mself\u001b[39m.config_dir))\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Step 3: load into configuration!\u001b[39;00m\n\u001b[32m    441\u001b[39m \u001b[38;5;28mself\u001b[39m._load_config(config_data)\n",
      "\u001b[31mOSError\u001b[39m: Could not find kaggle.json. Make sure it's located in /home/andreschirinos/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a818b",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "kaggle = {\n",
    "    \"title\": \"Peer-to-Peer Boliviano (BOB) Exchange Data\",\n",
    "    \"subtitle\": \"Github Actions ETL Pipeline\",\n",
    "    \"description\": \"This project contains the ETL pipeline for the Peer-to-Peer Boliviano (BOB) Exchange Data. The data is collected from various sources and transformed into a clean format for analysis. \\nThe pipeline includes data extraction, transformation, and loading processes, along with data quality checks.\\n\",\n",
    "    \"id\": \"andreschirinos/p2p-bob-exchange\",\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"name\": \"CC0-1.0\",\n",
    "            \"title\": \"CC0 1.0\",\n",
    "            \"path\": \"https://creativecommons.org/publicdomain/zero/1.0/\",\n",
    "        }\n",
    "    ],\n",
    "    \"resources\": [\n",
    "        {\n",
    "            \"path\": \"advertiser.parquet\",\n",
    "            \"description\": \"Advertiser data from the BOB exchange\",\n",
    "            \"schema\": {\n",
    "                \"fields\": [\n",
    "                    {\n",
    "                        \"name\": \"advertiser_userno\",\n",
    "                        \"order\": 0,\n",
    "                        \"description\": \"Unique identifier for the advertiser\",\n",
    "                        \"type\": \"string\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"advertiser_nickname\",\n",
    "                        \"order\": 1,\n",
    "                        \"description\": \"Nickname of the advertiser\",\n",
    "                        \"type\": \"string\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"advertiser_monthordercount\",\n",
    "                        \"order\": 2,\n",
    "                        \"description\": \"Number of orders placed by the advertiser in the last month\",\n",
    "                        \"type\": \"number\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"advertiser_monthfinishrate\",\n",
    "                        \"order\": 3,\n",
    "                        \"description\": \"Finish rate of the advertiser in the last month\",\n",
    "                        \"type\": \"number\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"advertiser_positiverate\",\n",
    "                        \"order\": 4,\n",
    "                        \"description\": \"Positive rate of the advertiser\",\n",
    "                        \"type\": \"number\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"advertiser_usertype\",\n",
    "                        \"order\": 5,\n",
    "                        \"description\": \"Type of the advertiser (e.g., user, merchant)\",\n",
    "                        \"type\": \"string\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"advertiser_usergrade\",\n",
    "                        \"order\": 6,\n",
    "                        \"description\": \"Grade of the advertiser\",\n",
    "                        \"type\": \"string\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"advertiser_u seridentity\",\n",
    "                        \"order\": 7,\n",
    "                        \"description\": \"Identity of the advertiser (e.g., MASS_MERCHANT, BLOCK_MERCHANT)\",\n",
    "                        \"type\": \"string\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"advertiser_viplevel\",\n",
    "                        \"order\": 8,\n",
    "                        \"description\": \"VIP level of the advertiser\",\n",
    "                        \"type\": \"number\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"advertiser_isblocked\",\n",
    "                        \"order\": 9,\n",
    "                        \"description\": \"Indicates if the advertiser is blocked\",\n",
    "                        \"type\": \"boolean\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"advertiser_activetimeinsecond\",\n",
    "                        \"order\": 10,\n",
    "                        \"description\": \"Active time of the advertiser in seconds\",\n",
    "                        \"type\": \"number\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"timestamp\",\n",
    "                        \"order\": 11,\n",
    "                        \"description\": \"Timestamp of the data collection\",\n",
    "                        \"type\": \"datetime\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"source\",\n",
    "                        \"order\": 12,\n",
    "                        \"description\": \"Source of the data (e.g, binance)\",\n",
    "                        \"type\": \"string\",\n",
    "                    },\n",
    "                ]\n",
    "            },\n",
    "            \"name\": \"advertiser\",\n",
    "            \"profile\": \"tabular-data-resource\",\n",
    "            \"title\": \"Advertiser Table\",\n",
    "            \"format\": \"format\",\n",
    "            \"encoding\": \"utf-8\",\n",
    "        }\n",
    "    ],\n",
    "    \"keywords\": [\n",
    "        \"p2p\",\n",
    "        \"exchange\",\n",
    "        \"data\",\n",
    "        \"pipeline\",\n",
    "        \"etl\",\n",
    "        \"bob\",\n",
    "        \"bolivia\",\n",
    "        \"cryptocurrency\",\n",
    "        \"bitcoin\",\n",
    "        \"blockchain\",\n",
    "    ],\n",
    "    \"name\": \"p2p-bob-exchange\",\n",
    "    \"homepage\": \"https://sociest.org\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"contributors\": [{\"title\": \"Andres Chirinos\", \"role\": \"author\"}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = os.path.join(data_dir, 'raw-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51153371",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Transformando datos de {input_file}...\")\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "df.columns = [col.strip().lower().replace(' ', '_').replace('.','_') for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1e859",
   "metadata": {},
   "source": [
    "# Advertiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb947b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa las tablas\n",
    "advertiser_cols = [col for col in df.columns if col.startswith(\"advertiser\") or col in [\"timestamp\", \"source\"]]\n",
    "df_advertiser = df[advertiser_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a905c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declara formatos\n",
    "custom_funcs = {\n",
    "    \"advertiser_userno\": lambda col: col.astype(str),\n",
    "    \"advertiser_monthordercount\": lambda col: col.astype(int),\n",
    "    \"advertiser_monthfinishrate\": lambda col: col.astype(float),\n",
    "    \"advertiser_positiverate\": lambda col: col.astype(float),\n",
    "    \"advertiser_usertype\": lambda col: col.astype(\"category\"),\n",
    "    \"advertiser_usergrade\": lambda col: col.astype(int),\n",
    "    \"advertiser_useridentity\": lambda col: col.astype(\"category\"),\n",
    "    \"advertiser_badges\": lambda col: col.astype(str),\n",
    "    \"advertiser_viplevel\": lambda col: col.fillna(0).astype(int),\n",
    "    \"advertiser_isblocked\": lambda col: col.astype(bool),\n",
    "    \"advertiser_activetimeinsecond\": lambda col: col.fillna(-1).astype(int),\n",
    "    \n",
    "    \"timestamp\": lambda col: pd.to_datetime(col, unit=\"s\"),\n",
    "    \"source\": lambda col: col.astype(\"category\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b232b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pone los formatos\n",
    "default_func = lambda col: col\n",
    "\n",
    "for col in df_advertiser.columns:\n",
    "    df_advertiser.loc[:, col] = custom_funcs.get(col, default_func)(df_advertiser[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62210af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"adv_advno\", \"advertiser_userno\"]].astype(str).groupby(\"advertiser_userno\").agg(','.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d0667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advertiser[\"advices\"] = df[[\"adv_advno\", \"advertiser_userno\"]].astype(str).groupby(\"advertiser_userno\")[\"adv_advno\"].transform(lambda x: ','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advertiser.drop_duplicates(subset=[\"advertiser_userno\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbcf9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advertiser.to_parquet(os.path.join(data_dir,'advertiser.parquet'), index=False)\n",
    "print(\"advertiser Transformación terminada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891bb29d",
   "metadata": {},
   "source": [
    "# Advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "advice_cols = [col for col in df.columns if (not col.startswith(\"advertiser\") or col in [\"advertiser_userno\"]) and not col in []]\n",
    "df_advice = df[advice_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1403e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declara formatos\n",
    "custom_funcs = {\n",
    "    \"adv_advno\": lambda col: col.astype(str),\n",
    "    \"adv_classify\": lambda col: col.astype(\"category\"),\n",
    "    \"adv_tradetype\": lambda col: col.astype(\"category\"),\n",
    "    \"adv_asset\": lambda col: col.astype(\"category\"),\n",
    "    \"adv_fiatunit\": lambda col: col.astype(\"category\"),\n",
    "    \"adv_price\": lambda col: col.astype(float),\n",
    "    \"adv_surplusamount\": lambda col: col.astype(float),\n",
    "    \"adv_tradablequantity\": lambda col: col.astype(float),\n",
    "    \"adv_maxsingletransamount\": lambda col: col.astype(float),\n",
    "    \"adv_minsingletransamount\": lambda col: col.astype(float),\n",
    "    \"adv_paytimelimit\": lambda col: col.astype(int),\n",
    "    \"adv_takeradditionalkycrequired\": lambda col: col.astype(bool),\n",
    "    \"adv_assetscale\": lambda col: col.astype(int),\n",
    "    \"adv_fiatscale\": lambda col: col.astype(int),\n",
    "    \"adv_pricescale\": lambda col: col.astype(int),\n",
    "    \"adv_fiatsymbol\": lambda col: col.astype(\"category\"),\n",
    "    \"adv_istradable\": lambda col: col.astype(bool),\n",
    "    \"adv_dynamicmaxsingletransamount\": lambda col: col.astype(float),\n",
    "    \"adv_minsingletransquantity\": lambda col: col.astype(float),\n",
    "    \"adv_maxsingletransquantity\": lambda col: col.astype(float),\n",
    "    \"adv_dynamicmaxsingletransquantity\": lambda col: col.astype(float),\n",
    "    \"adv_commissionrate\": lambda col: col.astype(float),\n",
    "    \"adv_issafepayment\": lambda col: col.astype(bool),\n",
    "    \n",
    "    \"adv_trademethods\": lambda col: col.apply(lambda x: \",\".join([method['identifier'] for method in eval(x)])),\n",
    "    \n",
    "    \"advertiser_userno\": lambda col: col.astype(str),\n",
    "\n",
    "    \"timestamp\": lambda col: pd.to_datetime(col, unit=\"s\"),\n",
    "    \"source\": lambda col: col.astype(\"category\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pone los formatos\n",
    "default_func = lambda col: col\n",
    "\n",
    "for col in df_advice.columns:\n",
    "    df_advice.loc[:, col] = custom_funcs.get(col, default_func)(df_advice[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advice.columns = df_advice.columns.str.replace(\"^adv_\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b377c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    api.dataset_download_file(kaggle[\"id\"], \"advice.parquet\", path=data_dir, force=True, quiet=False)\n",
    "    print(\"advice.parquet descargado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Descarga fallida: {e}. Creando advice.parquet vacío.\")\n",
    "    pd.DataFrame().to_parquet(os.path.join(data_dir, \"advice.parquet\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6566ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_advice = pd.read_parquet(os.path.join(data_dir, \"advice.parquet\"))\n",
    "\n",
    "# ensure both are DataFrames\n",
    "df_last_advice = pd.DataFrame(df_last_advice)\n",
    "df_advice = pd.DataFrame(df_advice)\n",
    "\n",
    "# make duplicate column names unique (if any)\n",
    "def _make_unique(cols):\n",
    "    seen = {}\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        if c in seen:\n",
    "            seen[c] += 1\n",
    "            out.append(f\"{c}_{seen[c]}\")\n",
    "        else:\n",
    "            seen[c] = 0\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "if df_last_advice.columns.duplicated().any():\n",
    "    df_last_advice.columns = _make_unique(df_last_advice.columns)\n",
    "if df_advice.columns.duplicated().any():\n",
    "    df_advice.columns = _make_unique(df_advice.columns)\n",
    "\n",
    "# avoid Categorical dtype concat issues by casting to object\n",
    "for df_ in (df_last_advice, df_advice):\n",
    "    for c in df_.columns:\n",
    "        if pd.api.types.is_categorical_dtype(df_[c]):\n",
    "            df_[c] = df_[c].astype(object)\n",
    "\n",
    "# align columns (add missing columns as NaN)\n",
    "all_cols = list(dict.fromkeys(list(df_last_advice.columns) + list(df_advice.columns)))\n",
    "df_last_advice = df_last_advice.reindex(columns=all_cols)\n",
    "df_advice = df_advice.reindex(columns=all_cols)\n",
    "\n",
    "# reset indexes and concat: append the new snapshot (df_advice) to the historical file (df_last_advice)\n",
    "df_combined = pd.concat([df_last_advice, df_advice], ignore_index=True, sort=False)\n",
    "\n",
    "# try to drop obvious duplicates: prefer to use advno+timestamp if available\n",
    "if set(['advno', 'timestamp']).issubset(df_combined.columns):\n",
    "    df_combined = df_combined.drop_duplicates(subset=['advno', 'timestamp']).reset_index(drop=True)\n",
    "elif 'advno' in df_combined.columns:\n",
    "    df_combined = df_combined.drop_duplicates(subset=['advno']).reset_index(drop=True)\n",
    "else:\n",
    "    df_combined = df_combined.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00272168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opcional: guardar de vuelta como histórico actualizado\n",
    "output_path = os.path.join(data_dir, \"advice.parquet\")\n",
    "df_combined.to_parquet(output_path, index=False, compression='snappy')\n",
    "\n",
    "print(f\"Concatenado histórico + snapshot -> {df_combined.shape}. Archivo guardado en: {output_path}\")\n",
    "\n",
    "# asignar a una variable para uso posterior\n",
    "df_advice_historical = df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1bd7c9",
   "metadata": {},
   "source": [
    "# Trade Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_methods_cols = [\n",
    "    col\n",
    "    for col in df.columns\n",
    "    if (col in [\"adv_advno\", \"adv_trademethods\"]) and not col in []\n",
    "]\n",
    "df_advice_trade_info = df[trade_methods_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advice_trade_table = df_advice_trade_info[\"adv_trademethods\"].apply(eval).explode()\n",
    "\n",
    "df_trade_methods_table = pd.json_normalize(df_advice_trade_table)\n",
    "\n",
    "df_trade_methods_table[\"adv_advno\"] = df_advice_trade_info.loc[df_advice_trade_table.index, \"adv_advno\"].values\n",
    "\n",
    "df_trade_methods_table = df_trade_methods_table.drop_duplicates()\n",
    "\n",
    "df_trade_methods = df_trade_methods_table.groupby(\"identifier\").agg({\n",
    "    \"adv_advno\": set,\n",
    "    \"tradeMethodName\": set,\n",
    "    \"tradeMethodShortName\": set,\n",
    "    \"tradeMethodBgColor\": set\n",
    "}).reset_index()\n",
    "\n",
    "df_trade_methods = df_trade_methods.applymap(lambda x: {str(i) for i in x if i is not None} if isinstance(x, set) else x)\n",
    "df_trade_methods = df_trade_methods.applymap(lambda x: ','.join(x) if isinstance(x, set) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trade_methods.to_parquet(os.path.join(data_dir,'trade_methods.parquet'), index=False)\n",
    "print(\"trade_methods Transformación terminada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68fe51",
   "metadata": {},
   "source": [
    "# Dashboard Summary Dataset\n",
    "\n",
    "Crear un dataset de resumen agregado para optimizar el dashboard.\n",
    "Este archivo contendrá datos pre-procesados por intervalos de tiempo, reduciendo drásticamente el tamaño y mejorando el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de advice para crear el resumen\n",
    "print(\"Cargando datos de advice para crear resumen...\")\n",
    "df_advice_full = pd.read_parquet(os.path.join(data_dir, 'advice.parquet'))\n",
    "\n",
    "print(f\"Datos cargados: {df_advice_full.shape}\")\n",
    "print(f\"Rango de fechas: {df_advice_full['timestamp'].min()} a {df_advice_full['timestamp'].max()}\")\n",
    "print(f\"Assets únicos: {df_advice_full['asset'].nunique()}\")\n",
    "print(f\"Tipos de trade: {df_advice_full['tradetype'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f73af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear resumen agregado por intervalo de tiempo\n",
    "def create_summary_dataset(df, freq='5min'):\n",
    "    \"\"\"\n",
    "    Crea un dataset de resumen agregado por intervalo de tiempo.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame con los datos completos\n",
    "    - freq: Frecuencia de agregación (5min, 15min, 1h, 1D, etc.)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame con datos agregados\n",
    "    \"\"\"\n",
    "    print(f\"Creando resumen con frecuencia: {freq}\")\n",
    "    \n",
    "    # Asegurar que timestamp es datetime\n",
    "    df = df.copy()\n",
    "    if df['timestamp'].dtype != 'datetime64[ns]':\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Agrupar por timestamp, asset, tradetype y source\n",
    "    summary = df.groupby([\n",
    "        pd.Grouper(key='timestamp', freq=freq),\n",
    "        'asset',\n",
    "        'tradetype',\n",
    "        'source'\n",
    "    ]).agg({\n",
    "        'price': ['mean', 'min', 'max', 'std', 'count'],\n",
    "        'tradablequantity': ['sum', 'mean', 'min', 'max'],\n",
    "        'surplusamount': ['sum', 'mean'],\n",
    "        'maxsingletransamount': ['mean', 'max'],\n",
    "        'minsingletransamount': ['mean', 'min'],\n",
    "        'advno': 'count'  # Número de anuncios\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Aplanar nombres de columnas\n",
    "    summary.columns = ['_'.join(col).strip('_') if col[1] else col[0] \n",
    "                       for col in summary.columns.values]\n",
    "    \n",
    "    # Renombrar para mayor claridad\n",
    "    summary = summary.rename(columns={\n",
    "        'advno_count': 'num_ads',\n",
    "        'price_count': 'num_transactions'\n",
    "    })\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Crear múltiples resúmenes con diferentes frecuencias\n",
    "print(\"\\n=== CREANDO RESÚMENES AGREGADOS ===\\n\")\n",
    "\n",
    "# Resumen de 5 minutos (para análisis detallado)\n",
    "summary_5min = create_summary_dataset(df_advice_full, freq='5min')\n",
    "print(f\"Resumen 5min: {summary_5min.shape} (reducción: {len(df_advice_full)/len(summary_5min):.1f}x)\")\n",
    "\n",
    "# Resumen de 1 hora (para análisis general)\n",
    "summary_1h = create_summary_dataset(df_advice_full, freq='1h')\n",
    "print(f\"Resumen 1h: {summary_1h.shape} (reducción: {len(df_advice_full)/len(summary_1h):.1f}x)\")\n",
    "\n",
    "# Resumen diario (para análisis histórico)\n",
    "summary_1d = create_summary_dataset(df_advice_full, freq='1D')\n",
    "print(f\"Resumen 1D: {summary_1d.shape} (reducción: {len(df_advice_full)/len(summary_1d):.1f}x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df256ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar ejemplo del resumen de 1 hora\n",
    "print(\"\\n=== EJEMPLO DEL RESUMEN (1 hora) ===\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "print(summary_1h.head())\n",
    "\n",
    "print(f\"\\nColumnas del resumen:\")\n",
    "for col in summary_1h.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(f\"\\nTipos de datos:\")\n",
    "print(summary_1h.dtypes)\n",
    "\n",
    "print(f\"\\nEstadísticas de memoria:\")\n",
    "print(f\"  Original: {df_advice_full.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(f\"  Resumen 5min: {summary_5min.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(f\"  Resumen 1h: {summary_1h.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(f\"  Resumen 1D: {summary_1d.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a890d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un resumen combinado optimizado para el dashboard\n",
    "# Este incluirá múltiples frecuencias en un solo archivo con un indicador\n",
    "\n",
    "print(\"\\n=== CREANDO RESUMEN COMBINADO PARA DASHBOARD ===\\n\")\n",
    "\n",
    "# Agregar columna de frecuencia a cada resumen\n",
    "summary_5min['frequency'] = '5min'\n",
    "summary_1h['frequency'] = '1h'  \n",
    "summary_1d['frequency'] = '1D'\n",
    "\n",
    "# Combinar todos los resúmenes\n",
    "dashboard_summary = pd.concat([\n",
    "    summary_5min,\n",
    "    summary_1h,\n",
    "    summary_1d\n",
    "], ignore_index=True)\n",
    "\n",
    "# Convertir a tipos de datos eficientes\n",
    "dashboard_summary['frequency'] = dashboard_summary['frequency'].astype('category')\n",
    "dashboard_summary['asset'] = dashboard_summary['asset'].astype('category')\n",
    "dashboard_summary['tradetype'] = dashboard_summary['tradetype'].astype('category')\n",
    "dashboard_summary['source'] = dashboard_summary['source'].astype('category')\n",
    "\n",
    "# Ordenar por timestamp\n",
    "dashboard_summary = dashboard_summary.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"Resumen combinado: {dashboard_summary.shape}\")\n",
    "print(f\"Reducción total de tamaño: {len(df_advice_full)/len(dashboard_summary):.1f}x\")\n",
    "print(f\"Memoria: {dashboard_summary.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(f\"\\nFrecuencias incluidas: {dashboard_summary['frequency'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceeea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el resumen combinado para el dashboard\n",
    "output_file = os.path.join(data_dir, 'dashboard_summary.parquet')\n",
    "dashboard_summary.to_parquet(output_file, index=False, compression='snappy')\n",
    "\n",
    "print(f\"\\n✅ Resumen guardado en: {output_file}\")\n",
    "print(f\"Tamaño del archivo: {os.path.getsize(output_file) / 1024**2:.2f} MB\")\n",
    "\n",
    "# También guardar solo el resumen de 1 hora (alternativa más ligera)\n",
    "output_file_1h = os.path.join(data_dir, 'dashboard_summary_1h.parquet')\n",
    "summary_1h_clean = summary_1h.drop('frequency', axis=1)\n",
    "summary_1h_clean.to_parquet(output_file_1h, index=False, compression='snappy')\n",
    "\n",
    "print(f\"✅ Resumen 1h guardado en: {output_file_1h}\")\n",
    "print(f\"Tamaño del archivo: {os.path.getsize(output_file_1h) / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMEN DE TRANSFORMACIÓN COMPLETADO\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
